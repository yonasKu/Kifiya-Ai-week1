{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge news and stock data on Date\n",
    "combined_df = pd.merge(news_df, stock_df[['Date', 'Daily_Return']], on='Date', how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average sentiment score per day (if multiple headlines per day)\n",
    "daily_sentiment = combined_df.groupby('Date').agg({\n",
    "    'vader_sentiment': 'mean',\n",
    "    'textblob_sentiment': 'mean',\n",
    "    'Daily_Return': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# Calculate correlation matrix\n",
    "correlation_matrix = daily_sentiment[['vader_sentiment', 'textblob_sentiment', 'Daily_Return']].corr()\n",
    "\n",
    "# Output correlations\n",
    "print(\"Correlation Matrix:\")\n",
    "print(correlation_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot sentiment scores vs daily returns\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# VADER Sentiment\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(daily_sentiment['vader_sentiment'], daily_sentiment['Daily_Return'], alpha=0.5)\n",
    "plt.title('VADER Sentiment vs Daily Returns')\n",
    "plt.xlabel('VADER Sentiment')\n",
    "plt.ylabel('Daily Returns')\n",
    "\n",
    "# TextBlob Sentiment\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(daily_sentiment['textblob_sentiment'], daily_sentiment['Daily_Return'], alpha=0.5)\n",
    "plt.title('TextBlob Sentiment vs Daily Returns')\n",
    "plt.xlabel('TextBlob Sentiment')\n",
    "plt.ylabel('Daily Returns')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between sentiment and stock returns:  nan\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Load the data\n",
    "news_data = pd.read_csv('../data/raw_analyst_ratings.csv')\n",
    "stock_data = pd.read_csv('../data/AAPL_historical_data.csv')\n",
    "\n",
    "# Parse dates\n",
    "news_data['date'] = pd.to_datetime(news_data['date'], errors='coerce')\n",
    "stock_data['Date'] = pd.to_datetime(stock_data['Date'], errors='coerce')\n",
    "\n",
    "# Remove timezone information to make both timezone-naive\n",
    "news_data['date'] = news_data['date'].dt.tz_localize(None)\n",
    "stock_data['Date'] = stock_data['Date'].dt.tz_localize(None)\n",
    "\n",
    "# Sentiment analysis\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "news_data['sentiment'] = news_data['headline'].apply(lambda x: analyzer.polarity_scores(x)['compound'])\n",
    "\n",
    "# Aggregate sentiment by date\n",
    "daily_sentiment = news_data.groupby(news_data['date'])['sentiment'].mean().reset_index()\n",
    "\n",
    "# Calculate daily stock returns\n",
    "stock_data['daily_return'] = stock_data['Close'].pct_change()\n",
    "\n",
    "# Merge sentiment data with stock data\n",
    "merged_data = pd.merge(daily_sentiment, stock_data, left_on='date', right_on='Date')\n",
    "\n",
    "# Calculate correlation\n",
    "correlation = merged_data[['sentiment', 'daily_return']].corr()\n",
    "\n",
    "print(\"Correlation between sentiment and stock returns: \", correlation.iloc[0, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No valid data to compute correlation.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Load the data\n",
    "news_data = pd.read_csv('../data/raw_analyst_ratings.csv')\n",
    "stock_data = pd.read_csv('../data/AAPL_historical_data.csv')\n",
    "\n",
    "# Parse dates\n",
    "news_data['date'] = pd.to_datetime(news_data['date'], errors='coerce')\n",
    "stock_data['Date'] = pd.to_datetime(stock_data['Date'], errors='coerce')\n",
    "\n",
    "# Remove timezone information to make both timezone-naive\n",
    "news_data['date'] = news_data['date'].dt.tz_localize(None)\n",
    "stock_data['Date'] = stock_data['Date'].dt.tz_localize(None)\n",
    "\n",
    "# Sentiment analysis\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "news_data['sentiment'] = news_data['headline'].apply(lambda x: analyzer.polarity_scores(x)['compound'])\n",
    "\n",
    "# Aggregate sentiment by date\n",
    "daily_sentiment = news_data.groupby(news_data['date'])['sentiment'].mean().reset_index()\n",
    "\n",
    "# Calculate daily stock returns\n",
    "stock_data['daily_return'] = stock_data['Close'].pct_change()\n",
    "\n",
    "# Merge sentiment data with stock data\n",
    "merged_data = pd.merge(daily_sentiment, stock_data, left_on='date', right_on='Date')\n",
    "\n",
    "# Drop rows with missing data (NaN)\n",
    "merged_data = merged_data.dropna(subset=['sentiment', 'daily_return'])\n",
    "\n",
    "# Check if there are enough data points to compute correlation\n",
    "if merged_data.empty:\n",
    "    print(\"No valid data to compute correlation.\")\n",
    "else:\n",
    "    # Calculate correlation\n",
    "    correlation = merged_data[['sentiment', 'daily_return']].corr()\n",
    "\n",
    "    print(\"Correlation between sentiment and stock returns: \", correlation.iloc[0, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily Sentiment Data:\n",
      "                 date  sentiment\n",
      "0 2011-04-27 21:01:48     0.0000\n",
      "1 2011-04-28 13:49:29     0.0000\n",
      "2 2011-04-28 15:00:36     0.2500\n",
      "3 2011-04-29 13:47:06     0.0000\n",
      "4 2011-04-29 16:11:05     0.7351\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 36011 entries, 0 to 36010\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype         \n",
      "---  ------     --------------  -----         \n",
      " 0   date       36011 non-null  datetime64[ns]\n",
      " 1   sentiment  36011 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(1)\n",
      "memory usage: 562.8 KB\n",
      "None\n",
      "Stock Data:\n",
      "        Date      Open      High       Low     Close  Adj Close     Volume  \\\n",
      "0 1980-12-12  0.128348  0.128906  0.128348  0.128348   0.098943  469033600   \n",
      "1 1980-12-15  0.122210  0.122210  0.121652  0.121652   0.093781  175884800   \n",
      "2 1980-12-16  0.113281  0.113281  0.112723  0.112723   0.086898  105728000   \n",
      "3 1980-12-17  0.115513  0.116071  0.115513  0.115513   0.089049   86441600   \n",
      "4 1980-12-18  0.118862  0.119420  0.118862  0.118862   0.091630   73449600   \n",
      "\n",
      "   Dividends  Stock Splits  daily_return  \n",
      "0        0.0           0.0           NaN  \n",
      "1        0.0           0.0     -0.052171  \n",
      "2        0.0           0.0     -0.073398  \n",
      "3        0.0           0.0      0.024751  \n",
      "4        0.0           0.0      0.028992  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10998 entries, 0 to 10997\n",
      "Data columns (total 10 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   Date          10998 non-null  datetime64[ns]\n",
      " 1   Open          10998 non-null  float64       \n",
      " 2   High          10998 non-null  float64       \n",
      " 3   Low           10998 non-null  float64       \n",
      " 4   Close         10998 non-null  float64       \n",
      " 5   Adj Close     10998 non-null  float64       \n",
      " 6   Volume        10998 non-null  int64         \n",
      " 7   Dividends     10998 non-null  float64       \n",
      " 8   Stock Splits  10998 non-null  float64       \n",
      " 9   daily_return  10997 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(8), int64(1)\n",
      "memory usage: 859.3 KB\n",
      "None\n",
      "Sentiment Date Range: 2011-04-27 21:01:48 to 2020-06-11 17:12:35\n",
      "Stock Date Range: 1980-12-12 00:00:00 to 2024-07-30 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(\"Daily Sentiment Data:\")\n",
    "print(daily_sentiment.head())\n",
    "print(daily_sentiment.info())\n",
    "\n",
    "print(\"Stock Data:\")\n",
    "print(stock_data.head())\n",
    "print(stock_data.info())\n",
    "\n",
    "\n",
    "print(\"Sentiment Date Range:\", daily_sentiment['date'].min(), \"to\", daily_sentiment['date'].max())\n",
    "print(\"Stock Date Range:\", stock_data['Date'].min(), \"to\", stock_data['Date'].max())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Date Type: datetime64[ns]\n",
      "Stock Date Type: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentiment Date Type:\", daily_sentiment['date'].dtype)\n",
    "print(\"Stock Date Type:\", stock_data['Date'].dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Data NaNs in 'date': 0\n",
      "Stock Data NaNs in 'Date': 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentiment Data NaNs in 'date':\", daily_sentiment['date'].isna().sum())\n",
    "print(\"Stock Data NaNs in 'Date':\", stock_data['Date'].isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily Sentiment Missing Values:\n",
      "date         0\n",
      "sentiment    0\n",
      "dtype: int64\n",
      "Stock Data Missing Values:\n",
      "Date            0\n",
      "Open            0\n",
      "High            0\n",
      "Low             0\n",
      "Close           0\n",
      "Adj Close       0\n",
      "Volume          0\n",
      "Dividends       0\n",
      "Stock Splits    0\n",
      "daily_return    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Daily Sentiment Missing Values:\")\n",
    "print(daily_sentiment.isna().sum())\n",
    "\n",
    "print(\"Stock Data Missing Values:\")\n",
    "print(stock_data.isna().sum())\n",
    "\n",
    "# Optionally, fill or drop missing values if necessary\n",
    "daily_sentiment = daily_sentiment.dropna()\n",
    "stock_data = stock_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 0 entries\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   date          0 non-null      datetime64[ns]\n",
      " 1   sentiment     0 non-null      float64       \n",
      " 2   Date          0 non-null      datetime64[ns]\n",
      " 3   Open          0 non-null      float64       \n",
      " 4   High          0 non-null      float64       \n",
      " 5   Low           0 non-null      float64       \n",
      " 6   Close         0 non-null      float64       \n",
      " 7   Adj Close     0 non-null      float64       \n",
      " 8   Volume        0 non-null      int64         \n",
      " 9   Dividends     0 non-null      float64       \n",
      " 10  Stock Splits  0 non-null      float64       \n",
      " 11  daily_return  0 non-null      float64       \n",
      "dtypes: datetime64[ns](2), float64(9), int64(1)\n",
      "memory usage: 132.0 bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Perform the merge again after ensuring both DataFrames have valid dates\n",
    "merged_data = pd.merge(daily_sentiment, stock_data, left_on='date', right_on='Date')\n",
    "\n",
    "# Drop rows with missing data in the merged DataFrame\n",
    "merged_data = merged_data.dropna(subset=['sentiment', 'daily_return'])\n",
    "\n",
    "# Recheck if there are any valid rows\n",
    "print(\"Merged Data Info:\")\n",
    "print(merged_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Date Range: 2011-04-27 to 2020-06-11\n",
      "Stock Date Range: 1980-12-15 to 2024-07-30\n"
     ]
    }
   ],
   "source": [
    "# Strip time information and ensure both columns are of the same type\n",
    "daily_sentiment['date'] = daily_sentiment['date'].dt.date\n",
    "stock_data['Date'] = stock_data['Date'].dt.date\n",
    "\n",
    "print(\"Sentiment Date Range:\", daily_sentiment['date'].min(), \"to\", daily_sentiment['date'].max())\n",
    "print(\"Stock Date Range:\", stock_data['Date'].min(), \"to\", stock_data['Date'].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Dates in Sentiment Data: [datetime.date(2011, 4, 27) datetime.date(2011, 4, 28)\n",
      " datetime.date(2011, 4, 29) ... datetime.date(2020, 6, 9)\n",
      " datetime.date(2020, 6, 10) datetime.date(2020, 6, 11)]\n",
      "Unique Dates in Stock Data: [datetime.date(1980, 12, 15) datetime.date(1980, 12, 16)\n",
      " datetime.date(1980, 12, 17) ... datetime.date(2024, 7, 26)\n",
      " datetime.date(2024, 7, 29) datetime.date(2024, 7, 30)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique Dates in Sentiment Data:\", daily_sentiment['date'].unique())\n",
    "print(\"Unique Dates in Stock Data:\", stock_data['Date'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35553 entries, 0 to 35552\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   date          35553 non-null  object \n",
      " 1   sentiment     35553 non-null  float64\n",
      " 2   Date          35553 non-null  object \n",
      " 3   Open          35553 non-null  float64\n",
      " 4   High          35553 non-null  float64\n",
      " 5   Low           35553 non-null  float64\n",
      " 6   Close         35553 non-null  float64\n",
      " 7   Adj Close     35553 non-null  float64\n",
      " 8   Volume        35553 non-null  int64  \n",
      " 9   Dividends     35553 non-null  float64\n",
      " 10  Stock Splits  35553 non-null  float64\n",
      " 11  daily_return  35553 non-null  float64\n",
      "dtypes: float64(9), int64(1), object(2)\n",
      "memory usage: 3.3+ MB\n",
      "None\n",
      "         date  sentiment        Date       Open       High        Low  \\\n",
      "0  2011-04-27     0.0000  2011-04-27  12.580000  12.583929  12.396429   \n",
      "1  2011-04-28     0.0000  2011-04-28  12.363929  12.491071  12.340000   \n",
      "2  2011-04-28     0.2500  2011-04-28  12.363929  12.491071  12.340000   \n",
      "3  2011-04-29     0.0000  2011-04-29  12.385000  12.641071  12.381071   \n",
      "4  2011-04-29     0.7351  2011-04-29  12.385000  12.641071  12.381071   \n",
      "\n",
      "       Close  Adj Close      Volume  Dividends  Stock Splits  daily_return  \n",
      "0  12.505357  10.560461   356213200        0.0           0.0     -0.000771  \n",
      "1  12.383929  10.457921   360959200        0.0           0.0     -0.009710  \n",
      "2  12.383929  10.457921   360959200        0.0           0.0     -0.009710  \n",
      "3  12.504643  10.559862  1006345200        0.0           0.0      0.009748  \n",
      "4  12.504643  10.559862  1006345200        0.0           0.0      0.009748  \n"
     ]
    }
   ],
   "source": [
    "stock_data['daily_return'] = stock_data['Close'].pct_change()\n",
    "stock_data = stock_data.dropna(subset=['daily_return'])\n",
    "# Merge sentiment data with stock data\n",
    "merged_data = pd.merge(daily_sentiment, stock_data, left_on='date', right_on='Date')\n",
    "\n",
    "# Drop rows with missing data\n",
    "merged_data = merged_data.dropna(subset=['sentiment', 'daily_return'])\n",
    "\n",
    "# Check the merged data\n",
    "print(\"Merged Data Info:\")\n",
    "print(merged_data.info())\n",
    "print(merged_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily Sentiment Sample:\n",
      "         date  sentiment\n",
      "0  2011-04-27     0.0000\n",
      "1  2011-04-28     0.0000\n",
      "2  2011-04-28     0.2500\n",
      "3  2011-04-29     0.0000\n",
      "4  2011-04-29     0.7351\n",
      "Stock Data Sample:\n",
      "         Date      Open      High       Low     Close  Adj Close    Volume  \\\n",
      "3  1980-12-17  0.115513  0.116071  0.115513  0.115513   0.089049  86441600   \n",
      "4  1980-12-18  0.118862  0.119420  0.118862  0.118862   0.091630  73449600   \n",
      "5  1980-12-19  0.126116  0.126674  0.126116  0.126116   0.097223  48630400   \n",
      "6  1980-12-22  0.132254  0.132813  0.132254  0.132254   0.101954  37363200   \n",
      "7  1980-12-23  0.137835  0.138393  0.137835  0.137835   0.106257  46950400   \n",
      "\n",
      "   Dividends  Stock Splits  daily_return  \n",
      "3        0.0           0.0      0.024751  \n",
      "4        0.0           0.0      0.028992  \n",
      "5        0.0           0.0      0.061029  \n",
      "6        0.0           0.0      0.048670  \n",
      "7        0.0           0.0      0.042199  \n"
     ]
    }
   ],
   "source": [
    "# Print a few rows from each DataFrame for inspection\n",
    "print(\"Daily Sentiment Sample:\")\n",
    "print(daily_sentiment.head())\n",
    "\n",
    "print(\"Stock Data Sample:\")\n",
    "print(stock_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between sentiment and stock returns:  nan\n",
      "Correlation between sentiment and stock returns:  nan\n"
     ]
    }
   ],
   "source": [
    "correlation = merged_data[['sentiment', 'daily_return']].corr()\n",
    "\n",
    "print(\"Correlation between sentiment and stock returns: \", correlation.iloc[0, 1])\n",
    "\n",
    "correlation = merged_data[['sentiment', 'daily_return']].corr()\n",
    "\n",
    "print(\"Correlation between sentiment and stock returns: \", correlation.iloc[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged Data Sample:\n",
      "Empty DataFrame\n",
      "Columns: [date, sentiment, Date, Open, High, Low, Close, Adj Close, Volume, Dividends, Stock Splits, daily_return]\n",
      "Index: []\n",
      "Daily Stock Returns Sample:\n",
      "        Date  daily_return\n",
      "0 1980-12-12           NaN\n",
      "1 1980-12-15     -0.052171\n",
      "2 1980-12-16     -0.073398\n",
      "3 1980-12-17      0.024751\n",
      "4 1980-12-18      0.028992\n",
      "Average Daily Sentiment Scores Sample:\n",
      "                 date  sentiment\n",
      "0 2011-04-27 21:01:48     0.0000\n",
      "1 2011-04-28 13:49:29     0.0000\n",
      "2 2011-04-28 15:00:36     0.2500\n",
      "3 2011-04-29 13:47:06     0.0000\n",
      "4 2011-04-29 16:11:05     0.7351\n",
      "Correlation between sentiment and stock returns:  nan\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Load the data\n",
    "news_data = pd.read_csv('../data/raw_analyst_ratings.csv')\n",
    "stock_data = pd.read_csv('../data/AAPL_historical_data.csv')\n",
    "\n",
    "# Parse dates\n",
    "news_data['date'] = pd.to_datetime(news_data['date'], errors='coerce')\n",
    "stock_data['Date'] = pd.to_datetime(stock_data['Date'], errors='coerce')\n",
    "\n",
    "# Remove timezone information\n",
    "news_data['date'] = news_data['date'].dt.tz_localize(None)\n",
    "stock_data['Date'] = stock_data['Date'].dt.tz_localize(None)\n",
    "\n",
    "# Sentiment Analysis\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "news_data['sentiment'] = news_data['headline'].apply(lambda x: analyzer.polarity_scores(x)['compound'])\n",
    "\n",
    "# Aggregate sentiment by date\n",
    "daily_sentiment = news_data.groupby(news_data['date'])['sentiment'].mean().reset_index()\n",
    "\n",
    "# Calculate daily stock returns\n",
    "stock_data['daily_return'] = stock_data['Close'].pct_change()\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Daily Sentiment Missing Values:\")\n",
    "print(daily_sentiment.isna().sum())\n",
    "\n",
    "print(\"Stock Data Missing Values:\")\n",
    "print(stock_data.isna().sum())\n",
    "\n",
    "# Merge sentiment data with stock data\n",
    "merged_data = pd.merge(daily_sentiment, stock_data, left_on='date', right_on='Date')\n",
    "\n",
    "# Drop rows with missing data in the merged DataFrame\n",
    "merged_data = merged_data.dropna(subset=['sentiment', 'daily_return'])\n",
    "\n",
    "# Display the merged data\n",
    "print(\"Merged Data Sample:\")\n",
    "print(merged_data.head())\n",
    "\n",
    "# Calculate and print daily stock returns\n",
    "print(\"Daily Stock Returns Sample:\")\n",
    "print(stock_data[['Date', 'daily_return']].head())\n",
    "\n",
    "# Calculate and print average daily sentiment scores\n",
    "print(\"Average Daily Sentiment Scores Sample:\")\n",
    "print(daily_sentiment.head())\n",
    "\n",
    "# Calculate correlation\n",
    "if merged_data.empty:\n",
    "    print(\"No valid data to compute correlation.\")\n",
    "else:\n",
    "    correlation = merged_data[['sentiment', 'daily_return']].corr()\n",
    "    print(\"Correlation between sentiment and stock returns: \", correlation.iloc[0, 1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
